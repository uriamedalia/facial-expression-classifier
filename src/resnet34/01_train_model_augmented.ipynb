{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uriamedalia/facial-expression-classifier/blob/split-notebooks/src/01_train_model_augmented.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "6961428e",
      "metadata": {
        "id": "6961428e",
        "outputId": "eb99c913-8822-4de2-b20c-b0d2d014cd16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'facial-expression-classifier'...\n",
            "remote: Enumerating objects: 34197, done.\u001b[K\n",
            "remote: Counting objects: 100% (13/13), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 34197 (delta 3), reused 8 (delta 1), pack-reused 34184 (from 3)\u001b[K\n",
            "Receiving objects: 100% (34197/34197), 106.93 MiB | 12.98 MiB/s, done.\n",
            "Resolving deltas: 100% (36/36), done.\n",
            "Updating files: 100% (35896/35896), done.\n",
            "/content/facial-expression-classifier/src/facial-expression-classifier/src\n",
            "✅ Train classes: ['disgust', 'neutral', 'sad', 'happy', 'angry', 'surprise', 'fear']\n",
            "✅ Test classes: ['disgust', 'neutral', 'sad', 'happy', 'angry', 'surprise', 'fear']\n"
          ]
        }
      ],
      "source": [
        "# Clone the GitHub repository\n",
        "!git clone --branch split-notebooks https://github.com/uriamedalia/facial-expression-classifier.git\n",
        "\n",
        "# Move into the project folder\n",
        "%cd facial-expression-classifier/src\n",
        "\n",
        "# Install dependencies\n",
        "!pip install -q torch torchvision pandas numpy matplotlib seaborn scikit-learn pillow\n",
        "\n",
        "# Check dataset structure\n",
        "import os\n",
        "\n",
        "train_path = \"../data/train\"\n",
        "test_path = \"../data/test\"\n",
        "\n",
        "print(\"✅ Train classes:\", os.listdir(train_path))\n",
        "print(\"✅ Test classes:\", os.listdir(test_path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hlGuab0Fmbc"
      },
      "source": [
        "# 01 - Train Model (Improved)\n",
        "\n",
        "Fine-tunes a ResNet34 model on FER2013 with data augmentation and class weighting."
      ],
      "id": "-hlGuab0Fmbc"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "qPHN6264Fmbe"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms, models\n",
        "from torch.utils.data import DataLoader\n",
        "from collections import Counter\n",
        "import os"
      ],
      "id": "qPHN6264Fmbe"
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wIuhKfJ9Fmbe"
      },
      "outputs": [],
      "source": [
        "# Data augmentation for training set\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomRotation(10),\n",
        "    transforms.RandomCrop(48, padding=4),\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Test transform only rescale and normalize\n",
        "test_transform = transforms.Compose([\n",
        "    transforms.Grayscale(num_output_channels=1),\n",
        "    transforms.Resize((48, 48)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "train_dir = '../data/train'\n",
        "test_dir = '../data/test'\n",
        "\n",
        "train_dataset = datasets.ImageFolder(root=train_dir, transform=train_transform)\n",
        "test_dataset = datasets.ImageFolder(root=test_dir, transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
      ],
      "id": "wIuhKfJ9Fmbe"
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "T0bpzFLBFmbe",
        "outputId": "8c6aa08f-1fb7-4ec5-cb94-9f310a655fab",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "Downloading: \"https://download.pytorch.org/models/resnet34-b627a593.pth\" to /root/.cache/torch/hub/checkpoints/resnet34-b627a593.pth\n",
            "100%|██████████| 83.3M/83.3M [00:00<00:00, 158MB/s]\n"
          ]
        }
      ],
      "source": [
        "# Model setup (ResNet34)\n",
        "model = models.resnet34(pretrained=True)\n",
        "model.conv1 = nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "model.fc = nn.Linear(model.fc.in_features, 7)\n",
        "\n",
        "# Unfreeze last block\n",
        "for param in model.layer4.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)"
      ],
      "id": "T0bpzFLBFmbe"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "57YInnenFmbf"
      },
      "outputs": [],
      "source": [
        "# Calculate class weights\n",
        "targets = train_dataset.targets\n",
        "counts = Counter(targets)\n",
        "weights = torch.tensor([1.0 / counts[i] for i in range(7)], dtype=torch.float32)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss(weight=weights)\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.0005)"
      ],
      "id": "57YInnenFmbf"
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Wu_pZeSbFmbf",
        "outputId": "833884ab-33b3-4d11-ee96-438b4e9a6efc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "Train Loss: 1.7218 Acc: 0.3474\n",
            "Val   Loss: 1.5891 Acc: 0.3980\n",
            "✅ Best model saved.\n",
            "Epoch 2/20\n",
            "Train Loss: 1.5621 Acc: 0.4139\n",
            "Val   Loss: 1.6308 Acc: 0.4019\n",
            "✅ Best model saved.\n",
            "Epoch 3/20\n",
            "Train Loss: 1.5608 Acc: 0.4214\n",
            "Val   Loss: 1.3841 Acc: 0.4817\n",
            "✅ Best model saved.\n",
            "Epoch 4/20\n",
            "Train Loss: 1.4433 Acc: 0.4584\n",
            "Val   Loss: 1.3427 Acc: 0.4879\n",
            "✅ Best model saved.\n",
            "Epoch 5/20\n",
            "Train Loss: 1.3785 Acc: 0.4869\n",
            "Val   Loss: 1.2341 Acc: 0.5410\n",
            "✅ Best model saved.\n",
            "Epoch 6/20\n",
            "Train Loss: 1.3346 Acc: 0.5030\n",
            "Val   Loss: 1.3480 Acc: 0.5011\n",
            "Epoch 7/20\n",
            "Train Loss: 1.2839 Acc: 0.5169\n",
            "Val   Loss: 1.3982 Acc: 0.4902\n",
            "Epoch 8/20\n",
            "Train Loss: 1.2806 Acc: 0.5196\n",
            "Val   Loss: 1.3144 Acc: 0.5258\n",
            "Epoch 9/20\n",
            "Train Loss: 1.2507 Acc: 0.5275\n",
            "Val   Loss: 1.2062 Acc: 0.5436\n",
            "✅ Best model saved.\n",
            "Epoch 10/20\n",
            "Train Loss: 1.2286 Acc: 0.5361\n",
            "Val   Loss: 1.2244 Acc: 0.5412\n",
            "Epoch 11/20\n",
            "Train Loss: 1.1880 Acc: 0.5472\n",
            "Val   Loss: 1.2110 Acc: 0.5508\n",
            "✅ Best model saved.\n",
            "Epoch 12/20\n",
            "Train Loss: 1.1680 Acc: 0.5582\n",
            "Val   Loss: 1.1503 Acc: 0.5698\n",
            "✅ Best model saved.\n",
            "Epoch 13/20\n",
            "Train Loss: 1.1355 Acc: 0.5632\n",
            "Val   Loss: 1.2781 Acc: 0.5281\n",
            "Epoch 14/20\n",
            "Train Loss: 1.1260 Acc: 0.5682\n",
            "Val   Loss: 1.5865 Acc: 0.5210\n",
            "Epoch 15/20\n",
            "Train Loss: 1.1742 Acc: 0.5505\n",
            "Val   Loss: 1.1695 Acc: 0.5808\n",
            "✅ Best model saved.\n",
            "Epoch 16/20\n",
            "Train Loss: 1.0773 Acc: 0.5793\n",
            "Val   Loss: 1.2592 Acc: 0.5685\n",
            "Epoch 17/20\n",
            "Train Loss: 1.0565 Acc: 0.5900\n",
            "Val   Loss: 1.1632 Acc: 0.5727\n",
            "Epoch 18/20\n",
            "Train Loss: 1.0416 Acc: 0.5955\n",
            "Val   Loss: 1.1897 Acc: 0.5832\n",
            "✅ Best model saved.\n",
            "Epoch 19/20\n",
            "Train Loss: 1.1063 Acc: 0.5787\n",
            "Val   Loss: 1.2145 Acc: 0.5490\n",
            "Epoch 20/20\n",
            "Train Loss: 1.0608 Acc: 0.5893\n",
            "Val   Loss: 1.0899 Acc: 0.5992\n",
            "✅ Best model saved.\n"
          ]
        }
      ],
      "source": [
        "# Training loop\n",
        "num_epochs = 20\n",
        "best_val_acc = 0.0\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    train_corrects = 0\n",
        "\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_loss += loss.item() * inputs.size(0)\n",
        "        train_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_loss = train_loss / len(train_dataset)\n",
        "    epoch_acc = train_corrects.double() / len(train_dataset)\n",
        "    print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n",
        "\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_corrects = 0\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in test_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "            val_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    val_loss /= len(test_dataset)\n",
        "    val_acc = val_corrects.double() / len(test_dataset)\n",
        "    print(f\"Val   Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        best_val_acc = val_acc\n",
        "        torch.save(model.state_dict(), '../models/resnet34_best_model.pth')\n",
        "        print(\"✅ Best model saved.\")"
      ],
      "id": "Wu_pZeSbFmbf"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}